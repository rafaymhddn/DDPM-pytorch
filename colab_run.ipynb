{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 sample.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 simple_diffusion_model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from train import train\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Arguments for ddpm training')\n",
    "parser.add_argument('--config', dest='config_path',\n",
    "                    default='config.yaml', type=str)\n",
    "args = parser.parse_args()\n",
    "train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sample import infer\n",
    "infer(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simple_diffusion_model import *\n",
    "from utils import *\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    # Download Dataset\n",
    "    # Transform to tensor and normalize\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "    # Load CIFAR-10 dataset\n",
    "    data = torchvision.datasets.CIFAR10(root=\".\", train=True, download=True, transform=transform)\n",
    "\n",
    "    # Display the images\n",
    "    #show_images(data)\n",
    "\n",
    "    # Image Size\n",
    "    IMG_SIZE = 32\n",
    "    BATCH_SIZE = 128\n",
    "\n",
    "    # Define beta schedule\n",
    "    T = 300\n",
    "    betas = linear_beta_schedule(timesteps=T)\n",
    "\n",
    "    # Pre-calculate different terms for closed form\n",
    "    alphas = 1. - betas\n",
    "    alphas_cumprod = torch.cumprod(alphas, axis=0)\n",
    "    alphas_cumprod_prev = F.pad(alphas_cumprod[:-1], (1, 0), value=1.0)\n",
    "    sqrt_recip_alphas = torch.sqrt(1.0 / alphas)\n",
    "    sqrt_alphas_cumprod = torch.sqrt(alphas_cumprod)\n",
    "    sqrt_one_minus_alphas_cumprod = torch.sqrt(1. - alphas_cumprod)\n",
    "    posterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)\n",
    "\n",
    "\n",
    "    # load data\n",
    "    data = load_transformed_dataset()\n",
    "    dataloader = DataLoader(data, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "\n",
    "    # Forward Diffusion test\n",
    "    # Simulate forward diffusion\n",
    "    \"\"\"image = next(iter(dataloader))[0]\n",
    "\n",
    "    plt.figure(figsize=(15,15))\n",
    "    plt.axis('off')\n",
    "    num_images = 10\n",
    "    stepsize = int(T/num_images)\n",
    "\n",
    "    for idx in range(0, T, stepsize):\n",
    "        t = torch.Tensor([idx]).type(torch.int64)\n",
    "        plt.subplot(1, num_images+1, int(idx/stepsize) + 1)\n",
    "        img, noise = forward_diffusion_sample(image, t)\n",
    "        show_tensor_image(img)\"\"\"\n",
    "    \n",
    "    model = SimpleUnet()\n",
    "    print(\"Num params: \", sum(p.numel() for p in model.parameters()))\n",
    "    #model\n",
    "\n",
    "    def get_loss(model, x_0, t):\n",
    "        x_noisy, noise = forward_diffusion_sample(x_0, t, device)\n",
    "        noise_pred = model(x_noisy, t)\n",
    "        return F.l1_loss(noise, noise_pred)\n",
    "    \n",
    "    model.to(device)\n",
    "    optimizer = Adam(model.parameters(), lr=0.001)\n",
    "    epochs = 100\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for step, batch in enumerate(dataloader):\n",
    "          optimizer.zero_grad()\n",
    "\n",
    "          t = torch.randint(0, T, (BATCH_SIZE,), device=device).long()\n",
    "          loss = get_loss(model, batch[0], t)\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "\n",
    "          if epoch % 5 == 0 and step == 0:\n",
    "            print(f\"Epoch {epoch} | step {step:03d} Loss: {loss.item()} \")\n",
    "            #sample_plot_image()\n",
    "    torch.save(model.state_dict())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
